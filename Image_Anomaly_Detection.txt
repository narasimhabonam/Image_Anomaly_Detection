import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import roc_curve, auc, roc_auc_score
from IPython.display import clear_output
import warnings
warnings.filterwarnings('ignore')

import kagglehub
path = kagglehub.dataset_download("odins0n/ucf-crime-dataset")

print("Path to dataset files:", path)

# HYPERPARAMETERS AND DIRECTORIES
train_dir = os.path.join(path, "Train")
test_dir = os.path.join(path, "Test")

# HYPERPARAMETERS AND DIRECTORIES
train_dir = os.path.join(path, "Train")
test_dir = os.path.join(path, "Test")
SEED = 12
IMG_HEIGHT = 64
IMG_WIDTH = 64
BATCH_SIZE = 64
EPOCHS = 1
LR =  0.00003
NUM_CLASSES = 14
CLASS_LABELS = ['Abuse','Arrest','Arson','Assault','Burglary','Explosion','Fighting',"Normal",'RoadAccidents','Robbery','Shooting','Shoplifting','Stealing','Vandalism']

preprocess_fun = tf.keras.applications.densenet.preprocess_input
train_datagen = ImageDataGenerator(horizontal_flip=True,
                                   width_shift_range=0.1,
                                   height_shift_range=0.05,
                                   rescale = 1./255,
                                   preprocessing_function=preprocess_fun
                                  )
test_datagen = ImageDataGenerator(rescale = 1./255,
                                  preprocessing_function=preprocess_fun
                                 )
train_generator = train_datagen.flow_from_directory(directory = train_dir,target_size = (IMG_HEIGHT ,IMG_WIDTH),batch_size = BATCH_SIZE,shuffle  = True ,
                                                    color_mode = "rgb",
                                                    class_mode = "categorical",
                                                    seed = SEED
                                                   )
test_generator = test_datagen.flow_from_directory(directory = test_dir,
                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),
                                                    batch_size = BATCH_SIZE,
                                                    shuffle  = False ,
                                                    color_mode = "rgb",
                                                    class_mode = "categorical",
                                                    seed = SEED
                                                  )

fig = px.bar(x = CLASS_LABELS,
             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] ,
             color = np.unique(train_generator.classes) ,
             color_continuous_scale="Emrld")
fig.update_xaxes(title="Classes")
fig.update_yaxes(title = "Number of Images")
fig.update_layout(showlegend = True,
    title = {
        'text': 'Train Data Distribution ',
        'y':0.95,
        'x':0.5,
        'xanchor': 'center',
        'yanchor': 'top'})
fig.show()

fig = px.bar(x = CLASS_LABELS,
             y = [list(test_generator.classes).count(i) for i in np.unique(test_generator.classes)] ,
             color = np.unique(train_generator.classes) ,
             color_continuous_scale="Emrld")
fig.update_xaxes(title="Classes")
fig.update_yaxes(title = "Number of Images")
fig.update_layout(showlegend = True,
    title = {
        'text': 'Test Data Distribution ',
        'y':0.95,
        'x':0.5,
        'xanchor': 'center',
        'yanchor': 'top'})
fig.show()

def feature_extractor(inputs):
    feature_extractor = tf.keras.applications.DenseNet121(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),
                                               include_top=False,
                                               weights="imagenet")(inputs)

    return feature_extractor

def classifier(inputs):
    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)
    x = tf.keras.layers.Dense(256, activation="relu")(x)
    x = tf.keras.layers.Dropout(0.3)(x)
    x = tf.keras.layers.Dense(1024, activation="relu")(x)
    x = tf.keras.layers.Dropout(0.5)(x)
    x = tf.keras.layers.Dense(512, activation="relu")(x)
    x = tf.keras.layers.Dropout(0.4) (x)
    x = tf.keras.layers.Dense(NUM_CLASSES, activation="softmax", name="classification")(x)

    return x

def final_model(inputs):
    densenet_feature_extractor = feature_extractor(inputs)
    classification_output = classifier(densenet_feature_extractor)

    return classification_output

def define_compile_model():

    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))
    classification_output = final_model(inputs)
    model = tf.keras.Model(inputs=inputs, outputs = classification_output)

    model.compile(optimizer=tf.keras.optimizers.SGD(LR),
                loss='categorical_crossentropy',
                metrics = [tf.keras.metrics.AUC()])

    return model

model = define_compile_model()
clear_output()
model.summary()

preds = model.predict(test_generator)
y_test = test_generator.classes
fig, c_ax = plt.subplots(1,1, figsize = (15,8))

def multiclass_roc_auc_score(y_test, y_pred, average="macro"):
    lb = LabelBinarizer()
    lb.fit(y_test)
    y_test = lb.transform(y_test)
    for (idx, c_label) in enumerate(CLASS_LABELS):
        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])
        c_ax.plot(fpr, tpr,lw=2, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))
    c_ax.plot(fpr, fpr, 'black',linestyle='dashed', lw=4, label = 'Random Guessing')
    return roc_auc_score(y_test, y_pred, average=average)

print('ROC AUC score:', multiclass_roc_auc_score(y_test , preds  , average = "micro"))
plt.xlabel('FALSE POSITIVE RATE', fontsize=18)
plt.ylabel('TRUE POSITIVE RATE', fontsize=16)
plt.legend(fontsize = 11.5)
plt.show()

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

checkpoint = ModelCheckpoint("best_model.h5", monitor="val_loss", save_best_only=True, verbose=1)
early_stopping = EarlyStopping(monitor="val_loss", patience=5, verbose=1, restore_best_weights=True)
model.save("anomaly_detection_model.h5")

import cv2
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.optimizers import Adam
from google.colab.patches import cv2_imshow  # For displaying images in Google Colab

# Define image height and width
IMG_HEIGHT = 64
IMG_WIDTH = 64

# Function to load and resize the image
def load_image(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH)):
    image = cv2.imread(image_path)
    image_resized = cv2.resize(image, target_size)  # Resize image to the target size
    return image_resized

# Build the Autoencoder model for anomaly detection
def build_autoencoder():
    input_img = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))  # Input shape of the image

    # Encoder
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)

    # Decoder
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)

    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer=Adam(), loss='binary_crossentropy')
    return autoencoder

# Function to detect anomalies in the image
def detect_anomalies(autoencoder, image, threshold=0.05):
    image_normalized = image.astype('float32') / 255.0  # Normalize the image
    reconstructed_image = autoencoder.predict(np.expand_dims(image_normalized, axis=0))

    # Calculate reconstruction error (Mean Squared Error)
    reconstruction_error = np.mean(np.power(image_normalized - reconstructed_image[0], 2), axis=-1)

    # Identify regions where the error is above the threshold
    anomaly_mask = reconstruction_error > threshold

    return anomaly_mask, reconstruction_error, reconstructed_image[0]

# Function to highlight anomalous regions in the image
def highlight_anomalous_regions(image, anomaly_mask):
    # Find contours of the anomalous regions
    contours, _ = cv2.findContours(anomaly_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Draw bounding boxes around the anomalous regions
    image_with_boxes = image.copy()
    for contour in contours:
        if cv2.contourArea(contour) > 100:  # Ignore small anomalies
            x, y, w, h = cv2.boundingRect(contour)
            cv2.rectangle(image_with_boxes, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red bounding box

    return image_with_boxes

# Main process
def main(image_path, output_image_path):
    # Step 1: Load and preprocess the image
    image = load_image(image_path)
    print(f"Image loaded: {image_path}")

    # Step 2: Build and train the Autoencoder model (use normal images for training)
    autoencoder = build_autoencoder()

    # Normalize image for training
    image_normalized = image.astype('float32') / 255.0  # Normalize image values between 0 and 1
    autoencoder.fit(np.expand_dims(image_normalized, axis=0), np.expand_dims(image_normalized, axis=0), epochs=10, batch_size=1)

    # Step 3: Detect anomalies in the image
    anomaly_mask, reconstruction_error, reconstructed_image = detect_anomalies(autoencoder, image)

    # Step 4: Highlight the anomalous regions in the image
    image_with_anomalies = highlight_anomalous_regions(image.copy(), anomaly_mask)

    # Step 5: Save the output image with highlighted anomalies
    cv2.imwrite(output_image_path, image_with_anomalies)
    print(f"Output image with anomaly detection saved as {output_image_path}")

    # Display the image (optional)
    cv2_imshow(image_with_anomalies)

# Example usage
image_path = "download.jpeg"  # Replace with the actual image path
output_image_path = "output_image_with_anomalies.jpg"  # Output image path
main(image_path, output_image_path)
